{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9151ba8-01ea-43d1-9fa0-ff9dcd6bc1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8881eee4-e6e3-4b4e-8396-8f2fcf2bcc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\roseh\\Desktop\\NYBG_R\\Lamont\\data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ca5a37-567b-4fbf-b428-2a17e9817882",
   "metadata": {},
   "source": [
    "### Clean metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9315088f-75ab-46dd-b0db-ff6ab9287130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list LDEO metadata sheet names\n",
    "sheets = ['220610_L','220613_L','220614_L','220617_L','220621_L','220629_L',\n",
    "          '220707_L','220711_L','220720_L','220803_L','220808_L','220818_L',\n",
    "          '220902_L','220916_L','221014_L']\n",
    "# read in excel sheets\n",
    "metadata = pd.read_excel(os.path.join(data_path,'Metadata_1.xlsx'), sheet_name=sheets,skiprows=3)\n",
    "# convert dictionary into list of dataframes, adding date column\n",
    "dataframes = []\n",
    "for name,group in metadata.items():\n",
    "    group['date'] = '20' + name[:6]\n",
    "    dataframes.append(group)\n",
    "# concatenate dataframes  \n",
    "metadata = pd.concat(dataframes)  \n",
    "# select desired columns  \n",
    "metadata = metadata[['Collar','Chamber Used','Temperature (° C)','Soil Moisture','Air Temp (° C)','Instrument','NDVI','date']]\n",
    "# convert date column to date data type\n",
    "metadata['date'] = pd.to_datetime(metadata['date'])\n",
    "# select only Respiration records\n",
    "metadata = metadata.loc[metadata['Chamber Used'] != 'NEE']\n",
    "# edit collar column\n",
    "metadata['Collar'] = metadata['Collar'].str[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cf2cb5-9edc-4007-848d-5d20f402b596",
   "metadata": {},
   "source": [
    "### Clean 7810 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81958cc4-a4ba-4725-b2e0-075d9b43676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 7810 csv files\n",
    "extension = 'csv'\n",
    "filenames_7810 = [i for i in glob.glob(os.path.join(data_path,'*7810.{}'.format(extension)))]\n",
    "# concatenate files\n",
    "combined_7810 = pd.concat([pd.read_csv(f,header=1) for f in filenames_7810 ])\n",
    "# select columns\n",
    "combined_7810 = combined_7810[['TA initial_value','FCO2_DRY','FCO2_DRY LIN','LABEL','DATE_TIME initial_value','FCO2_DRY LIN_CV']]\n",
    "# drop non-data columns\n",
    "combined_7810 = combined_7810.loc[combined_7810['TA initial_value'] != '[C]']\n",
    "# rename columns\n",
    "combined_7810.columns = ['chamber_temp','exp_flux','lin_flux','label','datetime','cv']\n",
    "# convert datetime column to date data type\n",
    "combined_7810['datetime'] = pd.to_datetime(combined_7810['datetime'])\n",
    "# convert other columns to float data type\n",
    "for col in ['chamber_temp','exp_flux','lin_flux','cv']:\n",
    "    combined_7810[col] = combined_7810[col].astype('float')\n",
    "# create column with just the date  \n",
    "combined_7810['date'] = pd.to_datetime(combined_7810['datetime'].dt.date) \n",
    "# create type column\n",
    "combined_7810['type'] = combined_7810['label'].str[3:5]\n",
    "# edit lable column\n",
    "combined_7810['label'] = combined_7810['label'].str[:6]\n",
    "# perform QC to remove rows with bad date values\n",
    "combined_7810 = combined_7810.loc[((combined_7810['lin_flux'] - combined_7810['exp_flux']).abs() / combined_7810['lin_flux'] < 0.1) | (combined_7810['cv'] < 1.2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b33819-7464-40dc-afb5-8ed58a1fc50c",
   "metadata": {},
   "source": [
    "### Clean 8100 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7462dfcc-032e-44ce-9676-35c29b3e6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 8100 csv files\n",
    "extension = 'csv'\n",
    "filenames_8100 = [i for i in glob.glob(os.path.join(data_path,'*8100.{}'.format(extension)))]\n",
    "# concatenate files\n",
    "combined_8100 = pd.concat([pd.read_csv(f,header=1) for f in filenames_8100])\n",
    "# select columns\n",
    "combined_8100 = combined_8100[['TA initial_value','FCO2_DRY','FCO2_DRY LIN','COMMENT','DATE initial_value','FCO2_DRY LIN_CV']]\n",
    "# remove non-data rows\n",
    "combined_8100 = combined_8100.loc[combined_8100['TA initial_value'] != '[C]']\n",
    "# rename columns\n",
    "combined_8100.columns = ['chamber_temp','exp_flux','lin_flux','label','datetime','cv']\n",
    "# convert datetime column to date data type\n",
    "combined_8100['datetime'] = pd.to_datetime(combined_8100['datetime'])\n",
    "# convert other columns to float data type\n",
    "for col in ['chamber_temp','exp_flux','lin_flux','cv']:\n",
    "    combined_8100[col] = combined_8100[col].astype('float')\n",
    "# create column with just the date  \n",
    "combined_8100['date'] = pd.to_datetime(combined_8100['datetime'].dt.date)\n",
    "# create type column\n",
    "combined_8100['type'] = combined_8100['label'].str[3:5]\n",
    "# edit lable column\n",
    "combined_8100['label'] = combined_8100['label'].str[:6]\n",
    "# perform QC to remove rows with bad date values\n",
    "combined_8100 = combined_8100.loc[((combined_8100['lin_flux'] - combined_8100['exp_flux']).abs() / combined_8100['lin_flux'] < 0.1) | (combined_8100['cv'] < 1.2)]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf07176-bc6a-455a-87ca-f38189b5430d",
   "metadata": {},
   "source": [
    "### Concatenate and merge cleaned files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa7798bb-b971-4eaf-a0d1-24d88b9085bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate 7810 and 8100 files\n",
    "flux = pd.concat([combined_7810,combined_8100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc9beb4a-e13b-4dd1-98dc-df107bb297a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge flux file with metadata file\n",
    "merge = flux.merge(metadata,left_on=['date','label'],right_on=['date','Collar'],how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ca86888-6fe7-43c8-b204-c2bc6e7cb1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read merged file to csv\n",
    "merge.to_csv(os.path.join(data_path,'lamont_all_main.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b63fbbd-fc71-4bb1-9611-73f6503311aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
